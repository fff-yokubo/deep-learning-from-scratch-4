[<img src="https://raw.githubusercontent.com/oreilly-japan/deep-learning-from-scratch-4/images/deep-learning-from-scratch-4.png" width="200px">](https://www.amazon.co.jp/dp/4873119758)

書籍『[ゼロから作るDeep Learning ❹ 強化学習編](https://www.amazon.co.jp/dp/4873119758)』(オライリー・ジャパン)のサポートサイトです。本書籍で使用するソースコードがまとめられています。


## ニュース
<a href="https://koki0702.github.io/dezero-p100/"><img src="https://raw.githubusercontent.com/oreilly-japan/deep-learning-from-scratch-4/images/p100.png" height="200px"></a>

本書の内容を確認するための「強化学習100題」を用意しています。

https://koki0702.github.io/dezero-p100/


## ファイル構成

|フォルダ名 |説明                         |
|:--        |:--                          |
|ch01       |1章で使用するソースコード    |
|...        |...                          |
|ch09       |9章で使用するソースコード    |
|common     |共通で使用するソースコード   |
|notebooks       |Jupyter Notebook形式のソースコード   |
|pytorch     |PyTorchに移植したソースコード   |


## Jupyter Notebook
本書のコードはJupyter Notebookでも用意しています。次の表にあるボタンをクリックすることで、Google ColabやKaggle Notebookなどのクラウドサービス上でNotebookを実行することができます。

| 章 | Colab | Kaggle | Studio Lab |
| :--- | :--- | :--- | :--- |
| 1章 バンディット問題 | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/01_bandit.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/01_bandit.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/01_bandit.ipynb) |
| 4章 動的計画法 | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/04_dynamic_programming.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/04_dynamic_programming.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/04_dynamic_programming.ipynb) |
| 5章 モンテカルロ法 | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/05_montecarlo.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/05_montecarlo.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/05_montecarlo.ipynb) |
| 6章 TD法 | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/06_temporal_difference.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/06_temporal_difference.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/06_temporal_difference.ipynb) |
| 7章 ニューラルネットワークとQ学習 | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/07_neural_networks.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/07_neural_networks.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/06_temporal_difference.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/07_neural_networks.ipynb) |
| 8章 DQN | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/08_dqn.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/08_dqn.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/08_dqn.ipynb) |
| 9章 方策勾配法  | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/09_policy_gradient.ipynb) | [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/09_policy_gradient.ipynb) | [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/oreilly-japan/deep-learning-from-scratch-4/blob/master/notebooks/09_policy_gradient.ipynb) |



## Pythonと外部ライブラリ
ソースコードを実行するには、下記のソフトウェアが必要です。

* Python 3.x（バージョン3系）
* NumPy
* Matplotlib
* OpenAI Gym
* DeZero （または PyTorch）


本書では、ディープラーニングのフレームワークとしてDeZeroを使います。DeZeroは「ゼロから作るDeep Learning」シリーズの3作目で作ったフレームワークです（ `pip install dezero` からインストールできます）。

PyTorchを使った実装は[pytorchフォルダ](https://github.com/oreilly-japan/deep-learning-from-scratch-4/tree/master/pytorch)にて提供しています。

## 実行方法
各章のフォルダに該当するコードがあります。
実行するためには、下記のとおりPythonコマンドを実行します（どのディレクトリからでも実行できます）。

```
$ python ch01/avg.py
$ python ch08/dqn.py

$ cd ch09
$ python actor_critic.py
```

## ライセンス

本リポジトリのソースコードは[MITライセンス](http://www.opensource.org/licenses/MIT)です。
商用・非商用問わず、自由にご利用ください。

## 正誤表

本書の正誤情報は以下のページで公開しています。

https://github.com/oreilly-japan/deep-learning-from-scratch-4/wiki/errata

本ページに掲載されていない誤植など間違いを見つけた方は、[japan@oreilly.co.jp](<mailto:japan@oreilly.co.jp>)までお知らせください。



## 作業メモ

### WSL2 + Ubuntu環境にてGUIを利用可能にする

https://qiita.com/nishiys/items/3b8c1670891f745c5a81

https://qiita.com/haraken_qiita/items/6983d0ca8c0f76bd021a

### 1. VcXsrvをインストール

https://sourceforge.net/projects/vcxsrv/
vcxsrv-64.1.20.14.0.installer.exe

#### VcXsrvの設定
xlaunch.exeという実行ファイルがあると思いますので, 起動します.

multiple window を選んで, 次へを選択
start no client を選んで, 次へを選択

clipboard を使用したければ, clipboardにチェックを入れます.
Additional parameters for VcXsrv という入力フォームに -ac と入力して, 次へを選択します.

![alt text](img/image.png)

設定内容を`C:\Program Files\VcXsrv\config.xlaunch`に保存。

#### VcXsrvの自動起動設定

Explorerにてshell:startupを開く。
ショートカットの登録→ターゲット
```
C:\Program Files\VcXsrv\xlaunch.exe" -run "C:\Program Files\VcXsrv\config.xlaunch"
```
として登録




### 2. 環境変数の設定
WSL2からVcXsrvに対して画面出力できるようにする。

``` shell
$ vi ~/.bashrc

# 末尾に以下を登録して保存
# Show GUI to windows from WSL2
export DISPLAY=`hostname`.mshome.net:0.0
export LIBGL_ALWAYS_INDIRECT=1
```

### 3. テストスクリプト生成

tkTest.pyとして保存。

``` python
from tkinter import *

root = Tk()
a = Label(root, text ="Hello World")
a.pack()

root.mainloop()

```

`$ python tkTest.py`でスクリプト実行

下記画面が出力されれば終了

![alt text](img/image-1.png)


### GUI


#### 1. qtwayland5のインストール
```
$ sudo apt install qtwayland5
```

#### 2. `/etc/environment`に下記を追加

```shell
QT_QPA_PLATFORM="xcb"
```


#### 3. `~/.bashrc`に下記を追加

``` shell
export QT_XCB_GL_INTEGRATION=none

```
